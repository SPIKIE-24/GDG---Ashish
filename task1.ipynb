{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f037bdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from scrapy import Selector\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import time\n",
    "\n",
    "# Helper Functions\n",
    "def scrape_nse_data():\n",
    "    url = \"https://www.nseindia.com/live_market/dynaContent/live_watch/equities_stock_watch.htm\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\",\n",
    "    }\n",
    "\n",
    "    # Using requests to scrape NSE data\n",
    "    session = requests.Session()\n",
    "    response = session.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Extract stock details (PE, EPS, 52-week high/low, etc.)\n",
    "    stock_data = []\n",
    "    rows = soup.find_all('tr')\n",
    "    for row in rows[1:]:  # Skip header\n",
    "        cols = row.find_all('td')\n",
    "        if len(cols) > 0:\n",
    "            stock = {\n",
    "                \"Stock\": cols[0].text.strip(),\n",
    "                \"LTP\": cols[1].text.strip(),\n",
    "                \"Change %\": cols[2].text.strip(),\n",
    "                \"52 Week High\": cols[3].text.strip(),\n",
    "                \"52 Week Low\": cols[4].text.strip(),\n",
    "                \"Market Cap\": cols[5].text.strip(),\n",
    "            }\n",
    "            stock_data.append(stock)\n",
    "    return pd.DataFrame(stock_data)\n",
    "\n",
    "def scrape_screener_data():\n",
    "    url = \"https://www.screener.in/company/\"\n",
    "    driver_path = \"<path_to_chromedriver>\"\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless\")\n",
    "\n",
    "    service = Service(driver_path)\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "    page_source = driver.page_source\n",
    "    driver.quit()\n",
    "\n",
    "    selector = Selector(text=page_source)\n",
    "\n",
    "    # Extract data from Screener using Scrapy\n",
    "    stock_data = []\n",
    "    rows = selector.xpath('//table[@class=\"data-table\"]//tr')\n",
    "    for row in rows:\n",
    "        stock = {\n",
    "            \"Stock\": row.xpath('./td[1]/text()').get(),\n",
    "            \"PE\": row.xpath('./td[2]/text()').get(),\n",
    "            \"EPS\": row.xpath('./td[3]/text()').get(),\n",
    "        }\n",
    "        stock_data.append(stock)\n",
    "\n",
    "    return pd.DataFrame(stock_data)\n",
    "\n",
    "def get_stock_returns(stock_list):\n",
    "    data = []\n",
    "    for stock in stock_list:\n",
    "        try:\n",
    "            ticker = yf.Ticker(stock)\n",
    "            hist = ticker.history(period=\"5y\")\n",
    "\n",
    "            # Calculate returns\n",
    "            close = hist['Close']\n",
    "            six_month_return = ((close[-1] / close[-126]) - 1) * 100 if len(close) >= 126 else None\n",
    "            one_year_return = ((close[-1] / close[-252]) - 1) * 100 if len(close) >= 252 else None\n",
    "            five_year_return = ((close[-1] / close[0]) - 1) * 100 if len(close) >= 1260 else None\n",
    "\n",
    "            data.append({\n",
    "                \"Stock\": stock,\n",
    "                \"6 Month Return\": six_month_return,\n",
    "                \"1 Year Return\": one_year_return,\n",
    "                \"5 Year Return\": five_year_return,\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data for {stock}: {e}\")\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Main Execution\n",
    "if __name__ == \"__main__\":\n",
    "    nse_data = scrape_nse_data()\n",
    "    screener_data = scrape_screener_data()\n",
    "\n",
    "    # Merge DataFrames\n",
    "    stock_data = pd.merge(nse_data, screener_data, on=\"Stock\", how=\"outer\")\n",
    "\n",
    "    # Get stock returns\n",
    "    stock_returns = get_stock_returns(stock_data['Stock'].tolist())\n",
    "\n",
    "    # Final DataFrame\n",
    "    final_df = pd.merge(stock_data, stock_returns, on=\"Stock\", how=\"outer\")\n",
    "    print(final_df.head())\n",
    "\n",
    "    # Save to CSV\n",
    "    final_df.to_csv(\"nifty50_stock_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
